{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77KqdisvIsa6",
        "outputId": "3b4944f1-ee7d-4a49-f658-8c58aa860237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/drive/MyDrive/Colab Notebooks/FictionVersev9.ipynb"
      ],
      "metadata": {
        "id": "PW6xKuv2IuVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NU9BWsP6CxuI"
      },
      "outputs": [],
      "source": [
        "!pip install diffusers > /dev/null\n",
        "!pip install diffusers==0.10.2 transformers scipy ftfy accelerate > /dev/null\n",
        "!pip install git+https://github.com/cloneofsimo/lora.git\n",
        "!pip install git+https://github.com/huggingface/transformers > /dev/null\n",
        "!pip install gradio > /dev/null\n",
        "!pip install openai > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/vibhork10/FictionVerse.git"
      ],
      "metadata": {
        "id": "_SVr1caiIVmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "UX_n5kLeLUXM",
        "outputId": "92713b5f-6c19-4d2a-a5d0-ce672eec67b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://d959bfb3eaad3bf925.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://d959bfb3eaad3bf925.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import cv2\n",
        "import shutil\n",
        "import subprocess\n",
        "from zipfile import ZipFile \n",
        "import os\n",
        "import random\n",
        "import gdown\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "from safetensors import safe_open\n",
        "from diffusers import StableDiffusionPipeline,DPMSolverMultistepScheduler\n",
        "import re\n",
        "import os\n",
        "import openai\n",
        "import gradio as gr\n",
        "os.makedirs(\"/content/models_saved\", exist_ok=True)\n",
        "os.makedirs(\"/content/images\", exist_ok=True)\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "story_type = {\n",
        "    \"fantasy\": \"You are an AI story writer assistant. You have to add a few lines to the story which the user has written.\",\n",
        "    \"science_fiction\": \"You are an AI story writer assistant. You have to add a few lines to the science fiction story which the user has written.\",\n",
        "    \"mystery\": \"You are an AI story writer assistant. You have to add a few lines to the mystery story which the user has written.\",\n",
        "    \"romance\": \"You are an AI story writer assistant. You have to add a few lines to the romance story which the user has written.\",\n",
        "    \"historical_fiction\": \"You are an AI story writer assistant. You have to add a few lines to the historical fiction story which the user has written.\",\n",
        "    \"horror\": \"You are an AI story writer assistant. You have to add a few lines to the horror story which the user has written.\",\n",
        "    \"adventure\": \"You are an AI story writer assistant. You have to add a few lines to the adventure story which the user has written.\",\n",
        "    \"comedy\": \"You are an AI story writer assistant. You have to add a few lines to the comedy story which the user has written.\",\n",
        "    \"None\":\"\",\n",
        "}\n",
        "\n",
        "model_name = \"gpt-3.5-turbo\"\n",
        "def generate_story(genre, user_input):\n",
        "    if genre != \"None\":\n",
        "      mymessages = [{\"role\": \"system\", \"content\": story_type[genre]}]\n",
        "      mymessages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "      response = openai.ChatCompletion.create(\n",
        "          model=model_name,\n",
        "          messages=mymessages\n",
        "      )\n",
        "\n",
        "      assistant_output = response['choices'][0]['message']['content']\n",
        "      # return user_input + \"\\n\" + assistant_output\n",
        "    else:\n",
        "      assistant_output = \"\"\n",
        "    return user_input + \" \" + assistant_output\n",
        "\n",
        "\n",
        "def change_textbox(choice):\n",
        "    if choice == \"object\":\n",
        "        return \"object\"\n",
        "    else:\n",
        "        return \"style\"\n",
        "\n",
        "\n",
        "def preview(files, sd: gr.SelectData):\n",
        "    print(files)\n",
        "    return files[sd.index].name\n",
        "import shutil\n",
        "\n",
        "def save_files(file_location, foldername, progress=gr.Progress(track_tqdm=True)):  \n",
        "    file_url = file_location.split(\"/\")[5]\n",
        "    filefull= \"https://docs.google.com/uc?export=download&confirm=t&id={}\".format(file_url)\n",
        "    liste = subprocess.run([\"wget\",filefull, \"-O\", foldername])\n",
        "    with zipfile.ZipFile(foldername, 'r') as zip:\n",
        "      zip.extractall('/content/')\n",
        "    temp=\"Folder saved to /content/\"+foldername\n",
        "    return gr.update(lines=1, visible=True,value=str(temp))\n",
        "\n",
        "def train_func(input, temp_type, progress=gr.Progress(track_tqdm=True)):\n",
        "  input_file = input.split(\".\")[0]\n",
        "  list_dir = subprocess.run([\"lora_pti\", \"--pretrained_model_name_or_path\",\"runwayml/stable-diffusion-v1-5\",\"--instance_data_dir\", \"/content/\"+input_file, \\\n",
        "                              \"--output_dir\", \"/content/output/\", \"--train_text_encoder\", \"--resolution\", \"512\", \"--train_batch_size\", \"1\", \"--gradient_accumulation_steps\", \"4\", \\\n",
        "                              \"--scale_lr\", \"--learning_rate_unet\", \"1e-4\", \"--learning_rate_text\", \"5e-5\", \"--learning_rate_ti\", \"5e-2\", \"--color_jitter\",\"--lr_scheduler\", \"linear\", \\\n",
        "                              \"--lr_warmup_steps\", \"0\", \"--placeholder_tokens\", \"<s1>\", \"--initializer_tokens\", \"man\", \"--use_template\", temp_type, \"--save_steps\", \"50\", \"--max_train_steps_ti\", \\\n",
        "                              \"1000\", \"--max_train_steps_tuning\", \"1000\",\"--perform_inversion\", \"True\", \"--clip_ti_decay\", \"--weight_decay_ti\", \"0.000\", \"--weight_decay_lora\", \"0.001\", \\\n",
        "                              \"--continue_inversion\", \\\n",
        "                              \"--continue_inversion_lr\", \\\n",
        "                              \"--device\", \"cuda:0\", \"--lora_rank\", \"16\"], capture_output=True)\n",
        "  l = input_file+temp_type\n",
        "  return gr.update(lines=1, visible=True,value=str(l))\n",
        "\n",
        "def textwitimage(text,image):\n",
        "  # Load the input image\n",
        "  h, w, _ = image.shape\n",
        "  print(h,w)\n",
        "  # Create a white background image of the same size\n",
        "  white_bg = np.full((h, w, 3), 255, dtype=np.uint8)\n",
        "\n",
        "  # Define the font and font parameters\n",
        "  font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "  font_thickness = 2\n",
        "  font_scale = 1\n",
        "\n",
        "  # Calculate the maximum width and height of the text box\n",
        "  text_box_width = int(0.9 * w)\n",
        "  text_box_height = int(0.9 * h)\n",
        "\n",
        "  # Split the text into words\n",
        "  words = text.split()\n",
        "\n",
        "  # Initialize the lines list with the first word\n",
        "  lines = [words[0]]\n",
        "  print(lines)\n",
        "  # Iterate over the remaining words and add them to lines, splitting lines as necessary\n",
        "  for word in words[1:]:\n",
        "      # Add the word to the current line\n",
        "      line = lines[-1] + ' ' + word\n",
        "      print(line)\n",
        "      # Get the size of the line\n",
        "      line_size, _ = cv2.getTextSize(line, font, font_scale, font_thickness)\n",
        "      print(line_size)\n",
        "      # If the line is too long, start a new line\n",
        "      if line_size[0] > text_box_width:\n",
        "          lines.append(word)\n",
        "      else:\n",
        "          lines[-1] = line\n",
        "\n",
        "  # Calculate the font size based on the height of the text box\n",
        "  font_size = 1\n",
        "  # Create a blank image to draw the text on\n",
        "  text_image = np.full((text_box_height, text_box_width, 3), 255, dtype=np.uint8)\n",
        "\n",
        "  # Draw the lines of text on the image, starting at the top\n",
        "  text_y = int(0.3*h)\n",
        "  for line in lines:\n",
        "      line_size, _ = cv2.getTextSize(line, font, font_size, font_thickness)\n",
        "      text_x = int((text_box_width - line_size[0]) / 2)\n",
        "      cv2.putText(white_bg, line, (text_x, text_y), font, font_size, (0, 0, 0), font_thickness)\n",
        "      text_y += line_size[1] + 10*font_size\n",
        "\n",
        "  # Calculate the position to place the text at the center\n",
        "  text_x = (w - text_box_width) // 2\n",
        "  text_y = (h - text_box_height) // 2\n",
        "\n",
        "  # Paste the text image onto the white background\n",
        "  #white_bg[text_y:text_y+text_box_height, text_x:text_x+text_box_width, :] = text_image\n",
        "\n",
        "  # Concatenate the input image and the white background image horizontally\n",
        "  concatenated_image = cv2.vconcat([image, white_bg])\n",
        "  return concatenated_image\n",
        "  \n",
        "def convert_model(artstyle, style, progress=gr.Progress(track_tqdm=True)):\n",
        "  output = \"/content/output/final_lora.safetensors\"\n",
        "  # artsyle_loc = \"/content/\"+artstyle\n",
        "  os.makedirs(\"/content/models_saved\", exist_ok=True)\n",
        "  os.rename(output, \"/content/models_saved/\"+str(artstyle)+\"_\"+str(style)+\".safetensors\")\n",
        "  return gr.update(lines=1, visible=True,value=\"Conversion has been completed model can be found at /content/models_saved/\")\n",
        "\n",
        "\n",
        "# def convert_vid(images_list):\n",
        "#   result = cv2.VideoWriter('/content/newanimation.mp4', \n",
        "#                           cv2.VideoWriter_fourcc(*'MP4V'),\n",
        "#                           2,(512,512))\n",
        "#   for img in images_list:\n",
        "#     image = img\n",
        "#     iamge = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "#     result.write(image)\n",
        "#   result.release()\n",
        "\n",
        "def return_value(prompt, image):\n",
        "  return prompt, image\n",
        "\n",
        "\n",
        "def load_sd(prompt, seed, line_box, org_text, options):        \n",
        "  with open(\"logger.txt\", \"a\") as f:\n",
        "    f.write(\"Prompt \"+str(prompt)+\"Seed \"+str(seed)+\"line_box \"+str(line_box)+\"options \"+str(options))                                                                                                                                                                                                                                                                                                                                                                         \n",
        "  if options == \"\":\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16)\n",
        "    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)   \n",
        "    pipe = pipe.to(\"cuda\")\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(int(seed))  \n",
        "    image = pipe(prompt, generator = generator, num_inference_steps=50).images[0] \n",
        "    image = np.asarray(image)\n",
        "    image = textwitimage(org_text,image)\n",
        "    os.makedirs(\"/content/images/\", exist_ok=True)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "    cv2.imwrite(\"/content/images/\"+str(line_box)+\".png\", image)\n",
        "  else:\n",
        "    from lora_diffusion import patch_pipe, tune_lora_scale, image_grid    \n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16)\n",
        "    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)   \n",
        "    model_loc= \"/content/models_saved/\"+options\n",
        "    patch_pipe(pipe,model_loc, patch_text=True,patch_ti=True, patch_unet=True)\n",
        "    pipe = pipe.to(\"cuda\")\n",
        "    sc = 0.6\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(int(seed))\n",
        "    tune_lora_scale(pipe.unet, sc)\n",
        "    tune_lora_scale(pipe.text_encoder,sc)\n",
        "    if options.split(\"_\")[1].split(\".\")[0] == \"style\":\n",
        "      image = pipe(prompt+\", in style of <s1>\", generator = generator, num_inference_steps=50).images[0]\n",
        "    else:\n",
        "      name_variable = \"<s1>\"\n",
        "      prompt = re.sub(r'<(.+?)>', name_variable, prompt)\n",
        "      with open(\"logger.txt\", \"a\") as f:\n",
        "        f.write(\"changed\"+prompt)\n",
        "      neg = \"double face, hands, wrist, Ugly, Duplicate, Extra fingers, Mutated hands, Poorly drawn face, Mutation, Deformed, Blurry, Bad anatomy, Bad proportions, Extra limbs, cloned face, Disfigured, Missing arms, Missing legs, Extra arms, Extra legs, Fused fingers, Too many fingers, Long neck, writing, letters, Multiple bodies, multiple heads, extra hands, extra fingers, ugly, skinny, extra leg, extra foot, blur, bad anatomy, double body, stacked body, fused hands, fused body, fused heads, fused legs, fused feet, multiple faces, conjoined, siamese twin, double faces, two faces, texts, watermarked, watermark, logo, face out of frame, stacked background, out of frame portrait, bucktoothed, cropped, yellow\"\n",
        "      image = pipe(prompt, negative_prompt=neg, generator = generator, num_inference_steps=50).images[0]\n",
        "    image = np.asarray(image)\n",
        "    image = textwitimage(org_text,image)\n",
        "    os.makedirs(\"/content/images/\", exist_ok=True)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "    cv2.imwrite(\"/content/images/\"+str(line_box)+\".png\", image)\n",
        "  return \"/content/images/\"+str(line_box)+\".png\"\n",
        "  \n",
        "def book_animate(input_text):\n",
        "  text_lines = input_text.split(\".\")\n",
        "  for i,new_line in enumerate(text_lines):\n",
        "    new_line = new_line.strip().replace(\"\\n\",\"\")\n",
        "    if (len(new_line) != 0):\n",
        "      prompt = new_line\n",
        "      yield prompt\n",
        "  yield prompt\n",
        "\n",
        "def change_textbox_style(choice):\n",
        "    if choice == \"object\":\n",
        "        return \"object\"\n",
        "    else:\n",
        "        return \"style\"\n",
        "def create_pdf():\n",
        "  from PIL import Image\n",
        "  images_list = os.listdir(\"/content/images/\")\n",
        "  images_list.sort()\n",
        "  images = []\n",
        "  img1 = Image.open(os.path.join(\"/content/images/\", images_list[0]))\n",
        "  img_1 = img1.convert('RGB')\n",
        "  for filename in images_list[1:]:\n",
        "      if filename.endswith('.png'):\n",
        "          # Open the image file using PIL\n",
        "          img = Image.open(os.path.join(\"/content/images/\", filename))\n",
        "\n",
        "          # Convert the image to PDF format\n",
        "          img_nw = img.convert('RGB')\n",
        "          images.append(img_nw)\n",
        "  \n",
        "  img_1.save('/content/convert.pdf', save_all=True, append_images=images)\n",
        "  return \"Converted to pdf\"\n",
        "\n",
        "\n",
        "def change_textbox(choice):\n",
        "    if choice == \"short\":\n",
        "        return gr.update(lines=5, visible=True, value=\"\")\n",
        "    elif choice == \"long\":\n",
        "        return gr.update(lines=30, visible=True, value=\"\")\n",
        "    else:\n",
        "        return gr.update(visible=False)\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Tab(\"Visual Story Generate\"):\n",
        "      with gr.Row():\n",
        "          with gr.Column():\n",
        "            radio = gr.Radio(\n",
        "                [\"short\", \"long\", \"none\"], label=\"Essay Length to Write?\"\n",
        "            )\n",
        "\n",
        "            fulltext = gr.Textbox(lines=2, label=\"Story Text\",interactive=True, placeholder=\"Write your story here .......\")\n",
        "            radio.change(fn=change_textbox, inputs=radio, outputs=fulltext)\n",
        "            genre_dropdown = gr.Dropdown(choices=list(story_type.keys()), info=\"Choose Genre\")\n",
        "            with gr.Row():\n",
        "              genaistory = gr.Button(\"Generate\")\n",
        "              saveopt = gr.Button(\"Save\") \n",
        "            aistory = gr.Textbox(label=\"AI-assisted Story\", interactive=False)\n",
        "              \n",
        "    \n",
        "            with gr.Row():\n",
        "              next = gr.Button(\"Next\")\n",
        "              prev = gr.Button(\"Previous\")\n",
        "              \n",
        "              clear = gr.Button(\"Clear\")\n",
        "                        \n",
        "          with gr.Column():\n",
        "            box_text = gr.Textbox(label=\"Line Selected\")\n",
        "            line_box = gr.Number(value=0, label=\"Line Count\")\n",
        "            seed_text = gr.Textbox(label=\"Seed Value\", value=random.randint(23,2147483647))\n",
        "            origline_text = gr.Textbox(label=\"Original Line Selected\", interactive=False)\n",
        "            models_list = os.listdir(\"/content/models_saved/\")\n",
        "           \n",
        "            with gr.Column():\n",
        "                radio = gr.Radio(\n",
        "                    [\"Use Style\"], label=\"Choose artist style\"\n",
        "                )\n",
        "                text1 = gr.Textbox(label=\"\")\n",
        "                text_options = gr.Dropdown(models_list, label=\"Use Model\", value=\"\", info=\"Choose to use the different artistic styles\", visible=False)\n",
        "                def select_models(choice):\n",
        "                  if choice==\"Use Style\":\n",
        "                    return {text1: \"Select models from below\", text_options: gr.update(visible=True, interactive=True)}\n",
        "                  else:\n",
        "                    return {text1: \"You chose to use the basic models\", text_options: gr.update(visible=False)}\n",
        "               \n",
        "                radio.change(fn=select_models, inputs=radio, outputs=[text1,text_options])\n",
        "            \n",
        "            with gr.Row():\n",
        "              submit1 = gr.Button(\"Generate\")\n",
        "              clear1 = gr.Button(\"Clear\") \n",
        "\n",
        "            def next_line(input_text, count):\n",
        "              count = int(count)\n",
        "              text_lines = input_text.split(\".\")\n",
        "              if count < len(text_lines):\n",
        "                new_line = text_lines[count].strip().replace(\"\\n\",\"\")\n",
        "                count += 1\n",
        "                if (len(new_line) != 0):\n",
        "                  return {box_text: new_line, line_box: count, origline_text: new_line}\n",
        "              return {box_text: \"Empty line\", line_box: count+1, origline_text: \"None\"}\n",
        "\n",
        "            def prev_line(input_text, count):\n",
        "              count = int(count)\n",
        "              text_lines = input_text.split(\".\")\n",
        "              if count < len(text_lines) and count > -1:\n",
        "                new_line = text_lines[count].strip().replace(\"\\n\",\"\")\n",
        "                count -= 1\n",
        "                if (len(new_line) != 0):\n",
        "                  return {box_text: new_line, line_box: count, origline_text: new_line}\n",
        "              return {box_text: \"Empty line\", line_box: count-1, origline_text: \"None\"}\n",
        "\n",
        "\n",
        "\n",
        "            \n",
        "            image = gr.Image(type=\"numpy\", label=\"Image Output\")\n",
        "            pdf_text = gr.Textbox(label=\"\")\n",
        "            # pdf = gr.File(label=\"download pdf\")\n",
        "            # pdf.select(lambda x: x, None, pdf_text)\n",
        "            with gr.Row():\n",
        "              submit2 = gr.Button(\"Submit\")\n",
        "              clear2 = gr.Button(\"Clear\")\n",
        "\n",
        "    with gr.Tab(\"Training Styles\"):\n",
        "      with gr.Row():\n",
        "          with gr.Column():\n",
        "              # f = gr.Textbox(label=\"Text id\")\n",
        "              google_share = gr.Textbox(label=\"Google Drive link\", placeholder=\"Place the shareable drive link of the file\")\n",
        "              zip_file = gr.Textbox(label=\"ZIP File\", placeholder=\"Give the name of the zip file to be downloaded like filename.zip\")\n",
        "              download = gr.Textbox(lines=1, label=\"\", visible=True)\n",
        "              # output = gr.Textbox(label=\"Output folder name\")\n",
        "              with gr.Row():\n",
        "                btn = gr.Button(\"Download\")\n",
        "                \n",
        "          with gr.Column():\n",
        "              radio = gr.Radio(\n",
        "                  [\"object\", \"Style\"], label=\"Choose Training Data Type\"\n",
        "              )\n",
        "              style_text = gr.Textbox(label=\"\")\n",
        "              radio.change(fn=change_textbox_style, inputs=radio, outputs=style_text)\n",
        "              output = gr.Textbox(lines=1, label=\"\", visible=True)\n",
        "              tr_btn = gr.Button(\"Train\")\n",
        "              artext = gr.Textbox(label=\"Model Name\", placeholder=\"Give a name to the newly saved model\")\n",
        "              artout = gr.Textbox(lines=1, label=\"\", visible=True)\n",
        "              con_btn = gr.Button(\"Convert\")\n",
        "      \n",
        "    # f.select(preview, f, i)ff\n",
        "    genaistory.click(generate_story, inputs=[genre_dropdown, fulltext], outputs=[aistory])\n",
        "    saveopt.click(lambda x: x, inputs=[aistory], outputs=[fulltext])\n",
        "    btn.click(save_files, inputs=[google_share,zip_file], outputs=[download], show_progress=True)\n",
        "    tr_btn.click(train_func, inputs=[zip_file,style_text], outputs=[output], show_progress=True)\n",
        "    con_btn.click(convert_model, inputs=[artext, style_text], outputs=[artout], show_progress=True)\n",
        "    next.click(next_line, inputs=[aistory, line_box], outputs=[box_text, line_box, origline_text], queue=False)\n",
        "    prev.click(prev_line, inputs=[aistory, line_box], outputs=[box_text, line_box, origline_text], queue=False)\n",
        "    clear.click(lambda: None, inputs=None, outputs=[aistory, fulltext],queue=False)\n",
        "    clear1.click(lambda: None, inputs=None, outputs=[box_text, origline_text, seed_text, line_box],queue=False)\n",
        "        # edit1.click(lambda x: x, inputs=[box_text], outputs=[box_text])\n",
        "    submit1.click(load_sd, inputs=[box_text, seed_text, line_box, origline_text, text_options], outputs=[image], queue=False)\n",
        "    submit2.click(create_pdf, inputs=None, outputs=[pdf_text])\n",
        "demo.queue()\n",
        "demo.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nx2Rv5OBQyy_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_JDYanmQy1a"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAbJ-6FSQy4p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9_43bscQy7N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXih9uMTQy90"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MP01StEvQzAb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}